{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesar variation sets de ACLEW + corpus espontáneo\n",
    "\n",
    "|   Lab/Sampling  | High Volubility | Random |        |\n",
    "|:---------------:|:---------------:|:------:|:------:|\n",
    "|       BER       |        10       | 10 (7) |   20   |\n",
    "|       SOD       |        6        |   9*   |   15   |\n",
    "|       WAR       |        7        | 10 (8) |   17   |\n",
    "|       .         |      **23**     | **29** | **52** |\n",
    "|    ROS-ACLEW    |        9        |   10   |   19   |\n",
    "|    ROS-Nuevos   |        13       |   13   |   26   |\n",
    "|        .        |      **22**     | **23** | **45** |\n",
    "| **Grand Total** |      **45**     | **52** | **97** |\n",
    "\n",
    "Los valores entre paréntesis son los que finalmente usamos en el paper anterior porque sacamos outliers.\n",
    "\n",
    "*: Sacaron uno que estaba mal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/macramole/Code/CHAFile/')\n",
    "#sys.path.insert(0, '/home/leandro/Code/CHAFile')\n",
    "from ChaFile import *\n",
    "import VariationSets as vss\n",
    "from log import Log\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultPath = \"./result.aclew.hv+random\"\n",
    "\n",
    "USE_DAD = False\n",
    "USE_SMARTVERBS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n",
    "\n",
    "#### Corpus Espontáneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesRandomSampling = glob(\"../aclew/randomSamplingResult/listos_cha/*.cha\")\n",
    "filesHighVol = glob(\"../aclew/highvolResults/listos_cha/*.cha\")\n",
    "dfCodeNums = pd.read_csv(\"../aclew/highvolResults/codenum-seleccionados.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACLEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclewPaths = [\n",
    "    \"../aclew/bajada-10022021/todos/spa/cha\",\n",
    "    \"../aclew/bajada-10022021/todos/eng/cha\",\n",
    "    \n",
    "    \"../aclew/highVolFromGit/allCHA/eng\",\n",
    "    \"../aclew/highVolFromGit/allCHA/spa\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclewCorporaDescriptionPath = \"../aclew/ACLEW_list_of_corpora.csv\"\n",
    "dfACLEW = pd.read_csv(aclewCorporaDescriptionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Log( os.path.join(resultPath,\"log.txt\"), settings = {\n",
    "    \"chaPaths\" : filesRandomSampling + filesHighVol + aclewPaths,\n",
    "    \"usingDAD\" : USE_DAD,\n",
    "    \"smartVerbs\" : USE_SMARTVERBS,\n",
    "    \"MAX_INTERVENCION_SPEAKER\" : vss.MAX_INTERVENCION_SPEAKER,\n",
    "    \"MAX_INTERVENCION_CHILD\" : vss.MAX_INTERVENCION_CHILD,\n",
    "    \"MAX_INTERVENCION_TO_CHILD\" : vss.MAX_INTERVENCION_TO_CHILD,\n",
    "    \"MAX_INTERVENCION_OTHER\" : vss.MAX_INTERVENCION_OTHER,\n",
    "    \"MAX_TIEMPO\" : vss.MAX_TIEMPO,\n",
    "    \n",
    "    \"MAX_INTERVENCION_SPEAKER_ADS\" : vss.MAX_INTERVENCION_SPEAKER_ADS,\n",
    "    \"MAX_INTERVENCION_TO_CHILD_ADS\" : vss.MAX_INTERVENCION_TO_CHILD_ADS,\n",
    "    \"MAX_INTERVENCION_TO_OCH_ADS\" : vss.MAX_INTERVENCION_TO_OCH_ADS,\n",
    "    \"MAX_INTERVENCION_OTHER_ADS\" : vss.MAX_INTERVENCION_OTHER_ADS,\n",
    "    \"MAX_TIEMPO_ADS\" : vss.MAX_TIEMPO_ADS,\n",
    "    \n",
    "    \"MAX_INTERVENCION_SPEAKER_OCH\" : vss.MAX_INTERVENCION_SPEAKER_OCH,\n",
    "    \"MAX_INTERVENCION_TO_CHILD_OCH\" : vss.MAX_INTERVENCION_TO_CHILD_OCH,\n",
    "    \"MAX_INTERVENCION_TO_OCH_OCH\" : vss.MAX_INTERVENCION_TO_OCH_OCH,\n",
    "    \"MAX_INTERVENCION_OTHER_OCH\" : vss.MAX_INTERVENCION_OTHER_OCH,\n",
    "    \"MAX_TIEMPO_OCH\" : vss.MAX_TIEMPO_OCH\n",
    "} )\n",
    "vss.log = log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recolectar números de línea\n",
    "\n",
    "Esto sólo se hace para los nuevos nuestros porque los archivos tienen más transcripción además de la seleccionada aleatoriamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling\n",
    "\n",
    "Estos tienen el hablante *code_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../aclew/randomSamplingResult/listos_cha/facundoa-a1-nsm.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/ummae-a1-nsb.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/amadeol-a1-nsm.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/nicolask-a1-nsm.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/demianm-a1-nsb.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/hannam-a1-nsb.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/nicolasb-a1-nsm.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/helenitab-a1-nsm.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/franciscoa-a2-nsb.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/amanday-a1-nsb.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/catalinap-a1-nsm.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/santinol-a1-nsb.c2elan.elan.cha\n",
      "../aclew/randomSamplingResult/listos_cha/juliaa-a1-nsm.c2elan.elan.cha\n",
      "CPU times: user 1.07 s, sys: 16.6 ms, total: 1.09 s\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filesLinesNumbersRandom = {}\n",
    "\n",
    "for f in filesRandomSampling:\n",
    "    log.log(f)\n",
    "    cha = ChaFile( f, \n",
    "                   ignoreSpeakers = [ SPEAKER_SILENCE, \n",
    "                                      SPEAKER_TARGET_CHILD, \n",
    "                                      \"note\", \n",
    "                                      \"context\",\n",
    "                                      \"on_off\", \n",
    "                                      \"code\" ]\n",
    "                   )\n",
    "    \n",
    "    codeNums = []\n",
    "\n",
    "    for l in cha.getLines():\n",
    "        if l[LINE_SPEAKER] == \"code_num\":\n",
    "            codeNums.append( l[LINE_BULLET] )\n",
    "\n",
    "    linesNumbers = []\n",
    "\n",
    "    for l in cha.getLines():\n",
    "        if l[LINE_SPEAKER] != \"code_num\":\n",
    "            for c in codeNums:\n",
    "                lineFrom = l[LINE_BULLET][0]\n",
    "                lineTo = l[LINE_BULLET][1]\n",
    "                \n",
    "                #si el inicio o el final de la emisión están dentro del code_num, entonces entra\n",
    "                if (lineFrom >= c[0] and lineFrom <= c[1]) or (lineTo >= c[0] and lineTo <= c[1]):\n",
    "                    linesNumbers.append( l[LINE_NUMBER] )\n",
    "                    break\n",
    "\n",
    "    \n",
    "    filesLinesNumbersRandom[ f ] = linesNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filesLinesNumbersRandom.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High volubility\n",
    "\n",
    "Estos tiene el hablante *COD\n",
    "\n",
    "Hay que chequear dfCodeNums para ver cuales hay que usar. Tienen algun problema como que el 0 lo toma mal entonces hay que pasarles un script que está en la carpeta y después hacer el if que se ve en el código.\n",
    "\n",
    "Esto es sólo para para los HighVol que hicimos nosotres, no los de ACLEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pedrov-a1-nsm.c2elan.elan.cha\n",
      "Warning: no language found\n",
      "miqueas-a2-nsb.elan.cha\n",
      "Warning: no language found\n",
      "donatow-a1-nsm.elan.cha\n",
      "Warning: no language found\n",
      "maileno-a1-nsb.elan.cha\n",
      "Warning: no language found\n",
      "simonm-a2-nsb.elan.cha\n",
      "Warning: no language found\n",
      "lucianal-a1-nsb.elan.cha\n",
      "Warning: no language found\n",
      "juanpablos-a1-nsm.elan.cha\n",
      "Warning: no language found\n",
      "felixv-a3-nsm.elan.cha\n",
      "Warning: no language found\n",
      "oliviaa-a1-nsm.elan.cha\n",
      "Warning: no language found\n",
      "cielor-a1-nsb.elan.cha\n",
      "Warning: no language found\n",
      "camilam-a1-nsm.elan.cha\n",
      "Warning: no language found\n",
      "tomash-a2-nsm.elan.cha\n",
      "Warning: no language found\n",
      "francescal-a1-nsm.elan.cha\n",
      "Warning: no language found\n",
      "CPU times: user 1.23 s, sys: 16.7 ms, total: 1.24 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "filesLinesNumbersHighVol = {}\n",
    "\n",
    "for f in filesHighVol:\n",
    "    filename = os.path.basename(f)\n",
    "    log.log(filename)\n",
    "\n",
    "    cha = ChaFile( f, \n",
    "                   ignoreSpeakers = [ SPEAKER_SILENCE, \n",
    "                                      SPEAKER_TARGET_CHILD, \n",
    "                                      \"*note\", \n",
    "                                      \"*context\",\n",
    "                                      \"*on_off\", \n",
    "                                      \"*code\" ],\n",
    "                    )\n",
    "\n",
    "    codeNumsIDs = list(dfCodeNums[ dfCodeNums.file == filename ][\"code num-id-anotacion\"])\n",
    "\n",
    "    if len(codeNumsIDs) == 0:\n",
    "        log.log(\"Critical error: No code nums\")\n",
    "\n",
    "    codeNums = []\n",
    "\n",
    "    for l in cha.getLines():\n",
    "        if l[LINE_SPEAKER] == \"COD\": \n",
    "            if l[LINE_UTTERANCE] == \"0 .\": #EL CERO LO ESTÁ TOMANDO MAL\n",
    "                codeNum = 0\n",
    "            else:\n",
    "                codeNum = int(l[LINE_UTTERANCE])\n",
    "\n",
    "            if codeNum in codeNumsIDs :\n",
    "                codeNums.append( l[LINE_BULLET] )   \n",
    "\n",
    "    if len(codeNums) != len(codeNumsIDs):\n",
    "        log.log(\"Critical error: len(codeNums) != len(codeNumsIDs)\")\n",
    "\n",
    "    linesNumbers = []\n",
    "\n",
    "    for l in cha.getLines():\n",
    "        if l[LINE_SPEAKER] != \"COD\":\n",
    "            for c in codeNums:\n",
    "                lineFrom = l[LINE_BULLET][0]\n",
    "                lineTo = l[LINE_BULLET][1]\n",
    "                \n",
    "                #si el inicio o el final de la emisión están dentro del code_num, entonces entra\n",
    "                if (lineFrom >= c[0] and lineFrom <= c[1]) or (lineTo >= c[0] and lineTo <= c[1]):\n",
    "                    linesNumbers.append( l[LINE_NUMBER] )\n",
    "                    break\n",
    "\n",
    "\n",
    "    filesLinesNumbersHighVol[ f ] = linesNumbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filesLinesNumbersHighVol.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvResult = [\n",
    "    [ \n",
    "        \"id\",\n",
    "        \"kid\",\n",
    "        \"std_mat_ed\",\n",
    "        \"ses\",\n",
    "        \"chaFile\",\n",
    "        \"speaker\",\n",
    "        \"addressee\",\n",
    "        \"long\",\n",
    "        \"wordCount\",\n",
    "        \"nounCount\",\n",
    "        \"verbCount\",\n",
    "        \"adjCount\",\n",
    "        \"repiteNoun\",\n",
    "        \"repiteVerb\",\n",
    "        \"repiteAdj\",\n",
    "        \"sampling\",\n",
    "        \"language\",\n",
    "        \"type\" #CDS, ADS, OCH\n",
    "    ]\n",
    "]\n",
    "\n",
    "csvCountResult = [\n",
    "    [ \n",
    "        \"kid\",\n",
    "        \"uttToChild\",\n",
    "        \"wordsToChild\",\n",
    "        \"nounsToChild\",\n",
    "        \"verbsToChild\",\n",
    "        \"adjsToChild\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sólo ACLEW\n",
    "\n",
    "Son 71 archivos contando inglés y español. No estamos tomando ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../aclew/bajada-10022021/todos/spa/cha/*.cha\n",
      "../aclew/bajada-10022021/todos/eng/cha/*.cha\n",
      "../aclew/highVolFromGit/allCHA/eng/*.cha\n",
      "../aclew/highVolFromGit/allCHA/spa/*.cha\n",
      "71 files found\n"
     ]
    }
   ],
   "source": [
    "chaFilesFound = []\n",
    "\n",
    "for path in aclewPaths:\n",
    "    g = \"%s/*.cha\" % path\n",
    "    log.log(g)\n",
    "    for f in glob(g):\n",
    "        chaFilesFound.append(f)\n",
    "\n",
    "log.log(\"%d files found\" % len(chaFilesFound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../aclew/bajada-10022021/todos/spa/cha/2534.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/6026.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/7903.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/1299.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/3510.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/9426.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/9909.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/9051.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/8788.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/spa/cha/0790.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/7758.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/4995.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/6035.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/9858.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/1618.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/3090.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/9854.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/3528.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/9527.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/3749.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/9398.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/5613.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/5750.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/3542.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/2535.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/1130.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/1196.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/1844.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/9755.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/8445.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/5959.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/2927.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/8924.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/0396.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/3634.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/3895.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/4483.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/9427.elan.cha...\n",
      "Processing ../aclew/bajada-10022021/todos/eng/cha/8768.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/9106.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/5134.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/4889.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/5792.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/2318.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/8560.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/0459.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/5980.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/0602.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/8684.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/0256.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/7928.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/3174.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/9733.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/5242.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/8602.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/8496.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/1836.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/9769.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/3439.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/7117.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/6045.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/eng/0990.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/9959.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/8569.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/5456.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/0873.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/2280.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/9378.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/5293.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/8340.elan.cha...\n",
      "Processing ../aclew/highVolFromGit/allCHA/spa/1092.elan.cha...\n"
     ]
    }
   ],
   "source": [
    "for chaFile in chaFilesFound:\n",
    "    log.log(\"Processing %s...\" % chaFile)\n",
    "    language = None\n",
    "    if \"eng\" in chaFile:\n",
    "        language = LANGUAGE_ENGLISH\n",
    "    elif \"spa\" in chaFile:\n",
    "        language = LANGUAGE_SPANISH\n",
    "        \n",
    "    sampling = \"random\"\n",
    "    if \"highVol\" in chaFile:\n",
    "        sampling = \"highVol\"\n",
    "        \n",
    "    filename = os.path.basename(chaFile)\n",
    "    kid = filename[:filename.find(\".\")]\n",
    "    ses = \"?\"\n",
    "    \n",
    "    std_mat_ed_list = dfACLEW[dfACLEW.aclew_id == int(kid)][\"std_mat_ed\"].tolist()\n",
    "    std_mat_ed = std_mat_ed_list[0]\n",
    "    if len(std_mat_ed_list) > 1:\n",
    "        log.log(\"Warning: ID %s is not unique in list corpora\" % kid)\n",
    "    \n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                           vss.CRITERIA_MOR, \n",
    "                                           resultPath,\n",
    "                                           useDAD = USE_DAD,\n",
    "                                           smartVerbs=USE_SMARTVERBS,\n",
    "                                           language = language,\n",
    "                                           vsType=vss.VS_TYPE_CDS)\n",
    "    \n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            sampling,\n",
    "            language,\n",
    "            vss.VS_TYPE_CDS\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "    \n",
    "    #ADS\n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                          vss.CRITERIA_MOR, \n",
    "                                          resultPath,\n",
    "                                          useDAD = USE_DAD,\n",
    "                                          smartVerbs = USE_SMARTVERBS,\n",
    "                                          language = language,\n",
    "                                          vsType=vss.VS_TYPE_ADS)\n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            sampling,\n",
    "            language,\n",
    "            vss.VS_TYPE_ADS\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "    \n",
    "    #OCH\n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                          vss.CRITERIA_MOR, \n",
    "                                          resultPath,\n",
    "                                          useDAD = USE_DAD,\n",
    "                                          smartVerbs = USE_SMARTVERBS,\n",
    "                                          language = language,\n",
    "                                          vsType=vss.VS_TYPE_OCH)\n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            sampling,\n",
    "            language,\n",
    "            vss.VS_TYPE_OCH\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "    \n",
    "    chaForCount = ChaFile( chaFile )\n",
    "    uttByAddressee = chaForCount.countUtterancesByAddressee()\n",
    "    wordsByAddressee = chaForCount.countWordsByAddressee()\n",
    "    \n",
    "    uttToChild = 0\n",
    "    wordsToChild = 0\n",
    "    nounsToChild = chaForCount.count(LINE_NOUNS, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    verbsToChild = chaForCount.count(LINE_VERBS, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    adjsToChild = chaForCount.count(LINE_ADJECTIVES, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    \n",
    "    if SPEAKER_TARGET_CHILD in uttByAddressee:\n",
    "        uttToChild = uttByAddressee[SPEAKER_TARGET_CHILD]\n",
    "    if SPEAKER_TARGET_CHILD in wordsByAddressee:\n",
    "        wordsToChild = wordsByAddressee[SPEAKER_TARGET_CHILD]\n",
    "    \n",
    "    csvCountResult.append([\n",
    "        kid,\n",
    "        uttToChild,\n",
    "        wordsToChild,\n",
    "        nounsToChild,\n",
    "        verbsToChild,\n",
    "        adjsToChild\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora los nuevos fuera de ACLEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando ../aclew/randomSamplingResult/listos_cha/facundoa-a1-nsm.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/ummae-a1-nsb.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/amadeol-a1-nsm.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/nicolask-a1-nsm.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/demianm-a1-nsb.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/hannam-a1-nsb.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/nicolasb-a1-nsm.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/helenitab-a1-nsm.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/franciscoa-a2-nsb.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/amanday-a1-nsb.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/catalinap-a1-nsm.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/santinol-a1-nsb.c2elan.elan.cha\n",
      "Procesando ../aclew/randomSamplingResult/listos_cha/juliaa-a1-nsm.c2elan.elan.cha\n"
     ]
    }
   ],
   "source": [
    "for chaFile in filesRandomSampling:\n",
    "    log.log(f\"Procesando {chaFile}\")\n",
    "    \n",
    "    filename = os.path.basename(chaFile)\n",
    "    kid = filename[:filename.find(\".\")]\n",
    "    \n",
    "    ses = kid.split(\"-\")[2]\n",
    "    std_mat_ed = \"?\"\n",
    "    \n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                           vss.CRITERIA_MOR, \n",
    "                                           resultPath,\n",
    "                                           useDAD = USE_DAD,\n",
    "                                           smartVerbs=USE_SMARTVERBS,\n",
    "                                           useLineNumbers=filesLinesNumbersRandom[chaFile],\n",
    "                                           verbose=False, language = LANGUAGE_SPANISH,\n",
    "                                           vsType=vss.VS_TYPE_CDS)\n",
    "    \n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            \"random\",\n",
    "            LANGUAGE_SPANISH,\n",
    "            vss.VS_TYPE_CDS\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "    \n",
    "    #ADS \n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                  vss.CRITERIA_MOR, \n",
    "                                  resultPath,\n",
    "                                  useDAD = USE_DAD,\n",
    "                                  smartVerbs = USE_SMARTVERBS,\n",
    "                                  useLineNumbers=filesLinesNumbersRandom[chaFile],\n",
    "                                  language = LANGUAGE_SPANISH,\n",
    "                                  verbose = False,\n",
    "                                  vsType=vss.VS_TYPE_ADS)\n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            \"random\",\n",
    "            LANGUAGE_SPANISH,\n",
    "            vss.VS_TYPE_ADS\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "        \n",
    "    #OCH \n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                  vss.CRITERIA_MOR, \n",
    "                                  resultPath,\n",
    "                                  useDAD = USE_DAD,\n",
    "                                  smartVerbs = USE_SMARTVERBS,\n",
    "                                  useLineNumbers=filesLinesNumbersRandom[chaFile],\n",
    "                                  language = LANGUAGE_SPANISH,\n",
    "                                  verbose = False,\n",
    "                                  vsType=vss.VS_TYPE_OCH)\n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            \"random\",\n",
    "            LANGUAGE_SPANISH,\n",
    "            vss.VS_TYPE_OCH\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "    \n",
    "    chaForCount = ChaFile( chaFile, includeLines=filesLinesNumbersRandom[chaFile], language = LANGUAGE_SPANISH )\n",
    "    uttByAddressee = chaForCount.countUtterancesByAddressee()\n",
    "    wordsByAddressee = chaForCount.countWordsByAddressee()\n",
    "    \n",
    "    uttToChild = 0\n",
    "    wordsToChild = 0\n",
    "    nounsToChild = chaForCount.count(LINE_NOUNS, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    verbsToChild = chaForCount.count(LINE_VERBS, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    adjsToChild = chaForCount.count(LINE_ADJECTIVES, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    \n",
    "    if SPEAKER_TARGET_CHILD in uttByAddressee:\n",
    "        uttToChild = uttByAddressee[SPEAKER_TARGET_CHILD]\n",
    "    if SPEAKER_TARGET_CHILD in wordsByAddressee:\n",
    "        wordsToChild = wordsByAddressee[SPEAKER_TARGET_CHILD]\n",
    "    \n",
    "    csvCountResult.append([\n",
    "        kid,\n",
    "        uttToChild,\n",
    "        wordsToChild,\n",
    "        nounsToChild,\n",
    "        verbsToChild,\n",
    "        adjsToChild\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High volubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando ../aclew/highvolResults/listos_cha/pedrov-a1-nsm.c2elan.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/miqueas-a2-nsb.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/donatow-a1-nsm.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/maileno-a1-nsb.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/simonm-a2-nsb.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/lucianal-a1-nsb.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/juanpablos-a1-nsm.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/felixv-a3-nsm.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/oliviaa-a1-nsm.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/cielor-a1-nsb.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/camilam-a1-nsm.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/tomash-a2-nsm.elan.cha\n",
      "Procesando ../aclew/highvolResults/listos_cha/francescal-a1-nsm.elan.cha\n"
     ]
    }
   ],
   "source": [
    "for chaFile in filesHighVol:\n",
    "    log.log(f\"Procesando {chaFile}\")\n",
    "    \n",
    "    filename = os.path.basename(chaFile)\n",
    "    kid = filename[:filename.find(\".\")]\n",
    "    \n",
    "    ses = ses = kid.split(\"-\")[2]\n",
    "    std_mat_ed = \"?\"\n",
    "    \n",
    "    \n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                           vss.CRITERIA_MOR, \n",
    "                                           resultPath,\n",
    "                                           useDAD = USE_DAD,\n",
    "                                           smartVerbs=USE_SMARTVERBS,\n",
    "                                           useLineNumbers=filesLinesNumbersHighVol[chaFile],\n",
    "                                           verbose=False, language = LANGUAGE_SPANISH,\n",
    "                                           vsType=vss.VS_TYPE_CDS)\n",
    "    \n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            \"highVol\",\n",
    "            LANGUAGE_SPANISH,\n",
    "            vss.VS_TYPE_CDS\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "    \n",
    "    #ADS\n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                  vss.CRITERIA_MOR, \n",
    "                                  resultPath,\n",
    "                                  useDAD = USE_DAD,\n",
    "                                  smartVerbs = USE_SMARTVERBS,\n",
    "                                  useLineNumbers=filesLinesNumbersHighVol[chaFile],\n",
    "                                  language = LANGUAGE_SPANISH,\n",
    "                                  verbose = False,\n",
    "                                  vsType=vss.VS_TYPE_ADS)\n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            \"highVol\",\n",
    "            LANGUAGE_SPANISH,\n",
    "            vss.VS_TYPE_ADS\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "        \n",
    "    #OCH\n",
    "    result = vss.getVariationSetsFromFile( chaFile, \n",
    "                                  vss.CRITERIA_MOR, \n",
    "                                  resultPath,\n",
    "                                  useDAD = USE_DAD,\n",
    "                                  smartVerbs = USE_SMARTVERBS,\n",
    "                                  useLineNumbers=filesLinesNumbersHighVol[chaFile],\n",
    "                                  language = LANGUAGE_SPANISH,\n",
    "                                  verbose = False,\n",
    "                                  vsType=vss.VS_TYPE_OCH)\n",
    "    for vs in result:\n",
    "        newRow = [\n",
    "            vs[\"id\"],\n",
    "            kid,\n",
    "            std_mat_ed,\n",
    "            ses,\n",
    "            chaFile,\n",
    "            vs[\"speaker\"],\n",
    "            vs[\"addressee\"],\n",
    "            vs[\"long\"],\n",
    "            vs[\"wordCount\"],\n",
    "            vs[\"nounCount\"],\n",
    "            vs[\"verbCount\"],\n",
    "            vs[\"adjCount\"],\n",
    "            vs[\"repiteNoun\"],\n",
    "            vs[\"repiteVerb\"],\n",
    "            vs[\"repiteAdj\"],\n",
    "            \"highVol\",\n",
    "            LANGUAGE_SPANISH,\n",
    "            vss.VS_TYPE_OCH\n",
    "        ]\n",
    "    \n",
    "        csvResult.append(newRow)\n",
    "    \n",
    "    chaForCount = ChaFile( chaFile, includeLines=filesLinesNumbersHighVol[chaFile], language = LANGUAGE_SPANISH )\n",
    "    uttByAddressee = chaForCount.countUtterancesByAddressee()\n",
    "    wordsByAddressee = chaForCount.countWordsByAddressee()\n",
    "    \n",
    "    uttToChild = 0\n",
    "    wordsToChild = 0\n",
    "    nounsToChild = chaForCount.count(LINE_NOUNS, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    verbsToChild = chaForCount.count(LINE_VERBS, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    adjsToChild = chaForCount.count(LINE_ADJECTIVES, ADDRESSEE_CHILD_DIRECTED, COUNT_TYPE_TOKENS)\n",
    "    \n",
    "    if SPEAKER_TARGET_CHILD in uttByAddressee:\n",
    "        uttToChild = uttByAddressee[SPEAKER_TARGET_CHILD]\n",
    "    if SPEAKER_TARGET_CHILD in wordsByAddressee:\n",
    "        wordsToChild = wordsByAddressee[SPEAKER_TARGET_CHILD]\n",
    "    \n",
    "    csvCountResult.append([\n",
    "        kid,\n",
    "        uttToChild,\n",
    "        wordsToChild,\n",
    "        nounsToChild,\n",
    "        verbsToChild,\n",
    "        adjsToChild\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(resultPath + \"/variation_sets.csv\", \"w\") as f :\n",
    "    csvWriter = csv.writer(f)\n",
    "    csvWriter.writerows(csvResult)\n",
    "with open(resultPath + \"/counts.csv\", \"w\") as f :\n",
    "    csvWriter = csv.writer(f)\n",
    "    csvWriter.writerows(csvCountResult)\n",
    "    \n",
    "log.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
